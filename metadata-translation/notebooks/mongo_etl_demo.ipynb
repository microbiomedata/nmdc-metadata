{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import jsonschema\n",
    "import requests\n",
    "from mongospawn.schema import dbschema_from_file, collschemas_for\n",
    "from pymongo import MongoClient, ReplaceOne\n",
    "from toolz import keyfilter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from functools import partial, reduce\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from dictdiffer import diff\n",
    "from pymongo import DeleteMany, DeleteOne, InsertOne, MongoClient, ReplaceOne, UpdateOne\n",
    "from toolz import assoc_in, compose, concat, dissoc, keyfilter, get_in, merge, merge_with\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def reset_database(db):\n",
    "    for coll_name in collschemas:\n",
    "        db.drop_collection(coll_name)\n",
    "        db.create_collection(\n",
    "            coll_name, validator={\"$jsonSchema\": collschemas[coll_name]}\n",
    "        )\n",
    "        db[coll_name].create_index(\"id\", unique=True)\n",
    "\n",
    "\n",
    "def jsonschema_for(collection_name=None):\n",
    "    if collection_name not in set(dbschema[\"properties\"]):\n",
    "        raise ValueError(\n",
    "            f'collection_name must be one of {set(dbschema[\"properties\"])}'\n",
    "        )\n",
    "    defn = dbschema[\"properties\"][collection_name][\"items\"][\"$ref\"].split(\"/\")[-1]\n",
    "    return dbschema[\"definitions\"][defn]\n",
    "\n",
    "\n",
    "def validator_for(collection):\n",
    "    return collection.options()[\"validator\"][\"$jsonSchema\"]\n",
    "\n",
    "\n",
    "def pick(whitelist, d):\n",
    "    return keyfilter(lambda k: k in whitelist, d)\n",
    "\n",
    "\n",
    "def conform(doc, collection_name=None):\n",
    "    \"\"\"Provides limited, conservative conformance on a docments.\n",
    "\n",
    "    - If additionalProperties is False, omit any supplied.\n",
    "    - If a field must be a list of strings, and a lone string is supplied, wrap it in a list.\n",
    "\n",
    "    \"\"\"\n",
    "    if collection_name not in set(dbschema[\"properties\"]):\n",
    "        raise ValueError(\n",
    "            f'collection_name must be one of {set(dbschema[\"properties\"])}'\n",
    "        )\n",
    "    defn = dbschema[\"properties\"][collection_name][\"items\"][\"$ref\"].split(\"/\")[-1]\n",
    "    schema = dbschema[\"definitions\"][defn]\n",
    "    if schema.get(\"additionalProperties\") is False:\n",
    "        doc = pick(list(schema[\"properties\"]), doc)\n",
    "    for k in list(doc.keys()):\n",
    "        if (\n",
    "            isinstance(doc[k], str)\n",
    "            and schema[\"properties\"].get(k, {}).get(\"type\") == \"array\"\n",
    "            and schema[\"properties\"][k][\"items\"][\"type\"] == \"string\"\n",
    "            and not isinstance(doc[k], list)\n",
    "        ):\n",
    "            doc[k] = [doc[k]]\n",
    "    return doc\n",
    "\n",
    "\n",
    "def validate(doc, collection_name=None, conform_doc=False):\n",
    "    if collection_name not in set(dbschema[\"properties\"]):\n",
    "        raise ValueError(\n",
    "            f'collection_name must be one of {set(dbschema[\"properties\"])}'\n",
    "        )\n",
    "    if conform_doc:\n",
    "        doc = conform(doc, collection_name=collection_name)\n",
    "    jsonschema.validate({collection_name: [doc]}, schema=dbschema)\n",
    "    return doc\n",
    "\n",
    "\n",
    "def fetch_json(url):\n",
    "    return requests.get(url).json()\n",
    "\n",
    "\n",
    "def fetch_and_validate_json(resource, collection_name=None, conform_doc=False):\n",
    "    \"\"\"Takes a URL or the pre-fetched resource (list or dict)\"\"\"\n",
    "    payload = fetch_json(resource) if isinstance(resource, str) else resource\n",
    "    validated = []\n",
    "    if isinstance(payload, list):\n",
    "        for doc in tqdm(payload):\n",
    "            validated.append(\n",
    "                validate(doc, collection_name=collection_name, conform_doc=conform_doc)\n",
    "            )\n",
    "    elif isinstance(payload, dict):\n",
    "        if set(payload) & set(dbschema[\"properties\"]):\n",
    "            for collection_name, docs in payload.items():\n",
    "                for doc in tqdm(docs, desc=collection_name):\n",
    "                    validated.append(\n",
    "                        validate(\n",
    "                            doc,\n",
    "                            collection_name=collection_name,\n",
    "                            conform_doc=conform_doc,\n",
    "                        )\n",
    "                    )\n",
    "        else:\n",
    "            validated.append(\n",
    "                validate(\n",
    "                    payload, collection_name=collection_name, conform_doc=conform_doc\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"Fetched JSON must be a JSON array or object\")\n",
    "    return validated\n",
    "\n",
    "\n",
    "def add_to_db(validated, db, collection_name=None):\n",
    "    if collection_name not in set(dbschema[\"properties\"]):\n",
    "        raise ValueError(\n",
    "            f'collection_name must be one of {set(dbschema[\"properties\"])}'\n",
    "        )\n",
    "    if isinstance(validated, list):\n",
    "        db[collection_name].bulk_write(\n",
    "            [ReplaceOne({\"id\": v[\"id\"]}, v, upsert=True) for v in validated]\n",
    "        )\n",
    "    elif isinstance(validated, dict):\n",
    "        if set(validated) & set(dbschema[\"properties\"]):\n",
    "            for collection_name, docs in validated.items():\n",
    "                db[collection_name].bulk_write(\n",
    "                    [ReplaceOne({\"id\": v[\"id\"]}, v, upsert=True) for v in docs]\n",
    "                )\n",
    "        else:\n",
    "            db[collection_name].bulk_write(\n",
    "                [ReplaceOne({\"id\": validated[\"id\"]}, validated, upsert=True)]\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"payload must be a list or dict\")\n",
    "\n",
    "\n",
    "def fetch_conform_and_persist(spec, db):\n",
    "    url = spec[\"url\"]\n",
    "    collection_name = spec[\"type\"]\n",
    "    print(f\"fetching {url} ({collection_name})\")\n",
    "    payload = fetch_and_validate_json(url, collection_name, conform_doc=True)\n",
    "    add_to_db(payload, db, collection_name)\n",
    "\n",
    "\n",
    "def fetch_conform_and_persist_from_manifest(spec, db):\n",
    "    error_urls = []\n",
    "    url_manifest = spec[\"url_manifest\"]\n",
    "    collection_name = spec[\"type\"]\n",
    "    urls = fetch_json(url_manifest)\n",
    "\n",
    "    pbar = tqdm(total=len(urls))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_url = {\n",
    "            executor.submit(\n",
    "                fetch_and_validate_json, url, collection_name, conform_doc=True\n",
    "            ): url\n",
    "            for url in urls\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            pbar.update(1)\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                payload = future.result()\n",
    "            except Exception as e:\n",
    "                error_urls.append((url, str(e)))\n",
    "            else:\n",
    "                add_to_db(payload, db, collection_name)\n",
    "\n",
    "    pbar.close()\n",
    "    return error_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "def coalesce_acronyms(set_name):\n",
    "    out = \"\"\n",
    "    for this_part, next_part in pairwise(set_name.split(\"_\")):\n",
    "        if len(this_part) == 1 and len(next_part) == 1:\n",
    "            out += this_part\n",
    "        elif next_part == \"set\":\n",
    "            out += this_part + \"_set\"\n",
    "        else:\n",
    "            out += this_part + \"_\"\n",
    "    return out\n",
    "\n",
    "def snake_case_set_name(object_name):\n",
    "    first_pass =  re.sub(r'(?<!^)(?=[A-Z])', '_', object_name).lower() + \"_set\"\n",
    "    return coalesce_acronyms(first_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmdc_schema_json_path = str(\n",
    "    Path.cwd().parent.parent.joinpath(\"schema\", \"nmdc.schema.json\")\n",
    ")\n",
    "dbschema = dbschema_from_file(nmdc_schema_json_path)\n",
    "\n",
    "###########################\n",
    "# Adjustments for GSP below\n",
    "###########################\n",
    "\n",
    "defined_object_names = set(dbschema[\"definitions\"])\n",
    "\n",
    "set_for_object_name = {\n",
    "    spec[\"items\"][\"$ref\"].split(\"#/definitions/\")[-1]: set_name\n",
    "    for set_name, spec in dbschema[\"properties\"].items()\n",
    "}\n",
    "\n",
    "existing_set_names = set(dbschema[\"properties\"])\n",
    "\n",
    "for object_without_set in (defined_object_names - set(set_for_object_name.keys())):\n",
    "    proposed_set_name = snake_case_set_name(object_without_set)\n",
    "    if proposed_set_name not in existing_set_names:\n",
    "        dbschema[\"properties\"][proposed_set_name] = {\n",
    "            \"description\": (f\"This property links a database object to the set of\"\n",
    "                            f\" {object_without_set} objects within it.\"),\n",
    "            \"items\": {\"$ref\": f\"#/definitions/{object_without_set}\"},\n",
    "            \"type\": \"array\",\n",
    "        }\n",
    "\n",
    "del dbschema[\"definitions\"][\"OmicsProcessing\"][\"additionalProperties\"]\n",
    "del dbschema[\"definitions\"][\"Biosample\"][\"additionalProperties\"]\n",
    "del dbschema[\"definitions\"][\"ReadQCAnalysisActivity\"][\"additionalProperties\"]\n",
    "del dbschema[\"definitions\"][\"MetaproteomicsAnalysisActivity\"][\"additionalProperties\"]\n",
    "dbschema = assoc_in(dbschema, [\"definitions\", \"ControlledTermValue\", \"properties\", \"term\", \"type\"], \"string\")\n",
    "del dbschema[\"definitions\"][\"ControlledTermValue\"][\"properties\"][\"term\"][\"$ref\"]\n",
    "dbschema = assoc_in(dbschema, [\"definitions\", \"MetagenomeAssembly\", \"properties\", \"scaf_l_gt50k\", \"type\"], \"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collschemas = collschemas_for(dbschema)\n",
    "\n",
    "# Reconstruct\n",
    "set_for_object_name = {\n",
    "    spec[\"items\"][\"$ref\"].split(\"#/definitions/\")[-1]: set_name\n",
    "    for set_name, spec in dbschema[\"properties\"].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\n",
    "    host=os.getenv(\"NMDC_MONGO_HOST\"),\n",
    "    username=\"dwinston_rw\",\n",
    "    password=os.getenv(\"NMDC_MONGO_RW_PWD\")\n",
    ")\n",
    "\n",
    "dbname = \"dwinston_dev\"\n",
    "db = client[dbname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activity_set',\n",
       " 'agent_set',\n",
       " 'attribute_value_set',\n",
       " 'biosample_processing_set',\n",
       " 'biosample_set',\n",
       " 'boolean_value_set',\n",
       " 'chemical_entity_set',\n",
       " 'controlled_term_value_set',\n",
       " 'data_object_set',\n",
       " 'database_set',\n",
       " 'environmental_material_term_set',\n",
       " 'functional_annotation_set',\n",
       " 'gene_product_set',\n",
       " 'genome_feature_set',\n",
       " 'geolocation_value_set',\n",
       " 'instrument_set',\n",
       " 'integer_value_set',\n",
       " 'mag_bin_set',\n",
       " 'mags_activity_set',\n",
       " 'metabolite_quantification_set',\n",
       " 'metabolomics_analysis_activity_set',\n",
       " 'metagenome_annotation_activity_set',\n",
       " 'metagenome_assembly_set',\n",
       " 'metaproteomics_analysis_activity_set',\n",
       " 'nom_analysis_activity_set',\n",
       " 'omics_processing_set',\n",
       " 'ontology_class_set',\n",
       " 'orthology_group_set',\n",
       " 'pathway_set',\n",
       " 'peptide_quantification_set',\n",
       " 'person_set',\n",
       " 'person_value_set',\n",
       " 'protein_quantification_set',\n",
       " 'quantity_value_set',\n",
       " 'reaction_participant_set',\n",
       " 'reaction_set',\n",
       " 'read_QC_analysis_activity_set',\n",
       " 'read_based_analysis_activity_set',\n",
       " 'study_set',\n",
       " 'text_value_set',\n",
       " 'timestamp_value_set',\n",
       " 'url_value_set']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_database(db)\n",
    "sorted(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fetch = [{\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/img_mg_annotation_objects.json\",\n",
    "    \"type\": \"metagenome_annotation_activity_set\",\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/img_mg_annotation_data_objects.json\",\n",
    "    \"type\": \"data_object_set\",\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/mt_annotation_objects.json\",\n",
    "    \"type\": \"metagenome_annotation_activity_set\"\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/mt_annotation_data_objects.json\",\n",
    "    \"type\": \"data_object_set\"\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/ReadbasedAnalysis_activity.json\",\n",
    "    \"type\": \"read_based_analysis_activity_set\"\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/ReadbasedAnalysis_data_objects.json\",\n",
    "    \"type\": \"data_object_set\"\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/MAGs_activity.json\",\n",
    "    \"type\": \"mags_activity_set\",\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/MAGs_data_objects.json\",\n",
    "    \"type\": \"data_object_set\"\n",
    "}, {\n",
    "    \"url\": \"https://nmdcdemo.emsl.pnnl.gov/metabolomics/registration/gcms_metabolomics_data_products.json\",\n",
    "    \"type\": \"data_object_set\"\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/stegen_MetaProteomicAnalysis_activity.json\",\n",
    "    \"type\": \"metaproteomics_analysis_activity_set\",\n",
    "}, {\n",
    "    \"url\": \"https://portal.nersc.gov/cfs/m3408/meta/stegen_emsl_analysis_data_objects.json\",\n",
    "    \"type\": \"data_object_set\"\n",
    "}, {\n",
    "    \"url\": \"https://nmdcdemo.emsl.pnnl.gov/nom/registration/ftms_nom_data_products.json\",\n",
    "    \"type\": \"data_object_set\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import identity\n",
    "\n",
    "metaP_field_map = {\n",
    "    'PeptideSequence': ('peptide_sequence', identity),\n",
    "    'sum(MASICAbundance)': ('peptide_sum_masic_abundance', int),\n",
    "    'SpectralCount': ('peptide_spectral_count', int),\n",
    "    'BestProtein': ('best_protein', identity),\n",
    "    'min(QValue)': ('min_q_value', float),\n",
    "}\n",
    "\n",
    "def map_fields(doc, field_map=None):\n",
    "    for k_old, todo in field_map.items():\n",
    "        if k_old in doc:\n",
    "            k_new, fn = todo\n",
    "            doc = assoc_in(doc,[k_new], fn(doc[k_old]))\n",
    "            doc = dissoc(doc, k_old)\n",
    "    return doc\n",
    "\n",
    "def correct_metaP_doc(doc):\n",
    "    if not \"has_peptide_quantifications\" in doc:\n",
    "        return doc\n",
    "    new_items = [map_fields(item, metaP_field_map) for item in doc[\"has_peptide_quantifications\"]]\n",
    "    doc = assoc_in(\n",
    "        doc,\n",
    "        [\"has_peptide_quantifications\"],\n",
    "        new_items,\n",
    "    )\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/img_mg_annotation_objects.json (metagenome_annotation_activity_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c27daf528e4b84b0ab6e5962b24888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/img_mg_annotation_data_objects.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f4fd558a8c41d68d134c87fade58e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/mt_annotation_objects.json (metagenome_annotation_activity_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5368671f137c4e4e97c0cad14135eae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/mt_annotation_data_objects.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f67fee4e75450c9072a2c98314993c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/ReadbasedAnalysis_activity.json (read_based_analysis_activity_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c74de9f831d4c869f57047cfa49c61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/ReadbasedAnalysis_data_objects.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b6d43c259543cd8e47cf4bfa222112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/MAGs_activity.json (mags_activity_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb2af2906284fa08b0dc96cc3631836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/MAGs_data_objects.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12ae52039c24d53899b47f547980630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://nmdcdemo.emsl.pnnl.gov/metabolomics/registration/gcms_metabolomics_data_products.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fdbd75f2914025909858452181e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/stegen_MetaProteomicAnalysis_activity.json (metaproteomics_analysis_activity_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bf5f5dee764f25bf82e976522c8a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://portal.nersc.gov/cfs/m3408/meta/stegen_emsl_analysis_data_objects.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa3737edaaf4a05accea1838752478d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching https://nmdcdemo.emsl.pnnl.gov/nom/registration/ftms_nom_data_products.json (data_object_set)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30e6d8f6aef494aa3a57dee9cf5ae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, spec in enumerate(to_fetch):\n",
    "    url = spec[\"url\"]\n",
    "    collection_name = spec[\"type\"]\n",
    "    print(f\"fetching {url} ({collection_name})\")\n",
    "    docs = fetch_json(url)\n",
    "    if not isinstance(docs, list):\n",
    "        docs = [docs]\n",
    "    docs = [correct_metaP_doc(d) for d in docs]\n",
    "    payload = fetch_and_validate_json(docs, collection_name, conform_doc=False)\n",
    "    add_to_db(payload, db, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b3525aac34484f8f369e1b95673d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "error_urls = fetch_conform_and_persist_from_manifest({\n",
    "    \"url_manifest\": (\"https://nmdcdemo.emsl.pnnl.gov/metabolomics/registration/\"\n",
    "                     \"gcms_metabolomics_metadata_products.json\"),\n",
    "    \"type\": \"metabolomics_analysis_activity_set\"\n",
    "}, db)\n",
    "len(error_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af721ea5f214dd9accc755966259ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "error_urls = fetch_conform_and_persist_from_manifest({\n",
    "    \"url_manifest\": (\"https://nmdcdemo.emsl.pnnl.gov/nom/registration/\"\n",
    "                     \"ftms_nom_metadata_products.json\"),\n",
    "    \"type\": \"nom_analysis_activity_set\"\n",
    "}, db)\n",
    "len(error_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_collection_names = [\n",
    "    name for name in db.list_collection_names()\n",
    "    if db[name].count_documents({}) > 1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['metabolomics_analysis_activity_set',\n",
       " 'read_based_analysis_activity_set',\n",
       " 'data_object_set',\n",
       " 'metagenome_annotation_activity_set',\n",
       " 'nom_analysis_activity_set',\n",
       " 'mags_activity_set']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_collection_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client = MongoClient(\n",
    "    host=os.getenv(\"NMDC_MONGO_HOST\"),\n",
    "    username=\"nmdc-admin\",\n",
    "    password=os.getenv(\"NMDC_MONGO_ADMIN_PWD\")\n",
    ")\n",
    "admin_dwinston_share = admin_client[\"dwinston_share\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_database_schema(db):\n",
    "    for coll_name in target_collection_names:\n",
    "        if coll_name not in db.list_collection_names():\n",
    "            print(\"creating\", coll_name)\n",
    "            db.create_collection(\n",
    "                coll_name, validator={\"$jsonSchema\": collschemas[coll_name]}\n",
    "            )\n",
    "            db[coll_name].create_index(\"id\", unique=True)\n",
    "        else:\n",
    "            print(\"updating\", coll_name)\n",
    "            db.command(\"collMod\", coll_name, validator={\"$jsonSchema\": collschemas[coll_name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating metabolomics_analysis_activity_set\n",
      "creating read_based_analysis_activity_set\n",
      "updating data_object_set\n",
      "updating metagenome_annotation_activity_set\n",
      "creating nom_analysis_activity_set\n",
      "updating mags_activity_set\n"
     ]
    }
   ],
   "source": [
    "reset_database_schema(admin_dwinston_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metabolomics_analysis_activity_set\n",
      "read_based_analysis_activity_set\n",
      "data_object_set\n",
      "metagenome_annotation_activity_set\n",
      "nom_analysis_activity_set\n",
      "mags_activity_set\n"
     ]
    }
   ],
   "source": [
    "db_share = client[\"dwinston_share\"]\n",
    "for name in target_collection_names:\n",
    "    docs = [dissoc(d, \"_id\") for d in db[name].find()]\n",
    "    print(name)\n",
    "    add_to_db(docs, db_share, collection_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MetaG annotations (`/global/project/projectdirs/m3408/www/meta/anno2/*_annotations.json`) are 155 JSON files totalling  ~83GB. To load them into MongoDB, I\n",
    "1. Set up a Globus transfer from NERSC DTN to a Globus Connect Personal endpoint on my laptop. I could e.g.\n",
    "```\n",
    "$ scp dtn01.nersc.gov:/global/project/projectdirs/m3408/www/meta/anno2/*_annotations.json .\n",
    "```\n",
    "but I chose to use Globus, and it works well.\n",
    "2. I have a bash script that uses GNU sed to transform each JSON file to a simple json array, as expected by `mongoimport`:\n",
    "\n",
    "```bash\n",
    "# trim.sh\n",
    "\n",
    "task(){\n",
    "    echo $datafile\n",
    "    gsed -e '1,2d' -e '$d' -e '3i\\[' $datafile > anno2/$(basename $datafile)\n",
    "}\n",
    "\n",
    "for datafile in ~/globus-nersc/nmdc/m3408/www/meta/anno2/*_annotations.json; do\n",
    "    task $datafile &\n",
    "done\n",
    "```\n",
    "I use `ps aux | grep gsed | wc -l` to monitor the progress of the parallel sed tasks. I found that trying to do this head/tail file trimming by `json.load`ing the files in Python and resaving was quite slow because the JSON files are individually quite large.\n",
    "3. I have a bash script that `mongoimport`s each json array file to the database\n",
    "```bash\n",
    "# mongoimport.sh\n",
    "\n",
    "n=$(ls anno2/*_annotations.json | wc -l | xargs) # `| xargs` to trim whitespace\n",
    "i=1\n",
    "for datafile in anno2/*_annotations.json; do\n",
    "    echo \"($i of $n): $datafile\"\n",
    "    mongoimport --uri \"mongodb://<user>:<pwd>@<host>/?authSource=admin\" \\\n",
    "        --jsonArray -d dwinston_share -c raw.functional_annotation_set \\\n",
    "        -j 8 $datafile\n",
    "    i=$((i+1))\n",
    "done\n",
    "```\n",
    "specifying multiple (8 in this case) insertion workers per import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time()\n",
    "\n",
    "print(f\"{toc - tic} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdc",
   "language": "python",
   "name": "nmdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
