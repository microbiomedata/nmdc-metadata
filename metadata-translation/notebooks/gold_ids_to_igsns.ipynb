{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from functools import partial, reduce\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from dictdiffer import diff\n",
    "from pymongo import DeleteMany, InsertOne, UpdateOne, MongoClient\n",
    "from toolz import assoc_in, compose, concat, dissoc, get_in, merge, merge_with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Re-)load existing NMDC DB from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('../src/data/nmdc_database.json.zip') as myzip:\n",
    "    with myzip.open('nmdc_database.json') as f:\n",
    "        nmdc_database = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activity_set', 'biosample_set', 'data_object_set', 'foo', 'omics_processing_set', 'study_set']\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(\n",
    "    host=os.getenv(\"NMDC_MONGO_HOST\"),\n",
    "    username=\"dwinston_rw\",\n",
    "    password=os.getenv(\"NMDC_MONGO_RW_PWD\"))\n",
    "dbname = \"dwinston_share\"\n",
    "db = client[dbname]\n",
    "\n",
    "for collection in nmdc_database:\n",
    "    db[collection].delete_many({})\n",
    "    db[collection].insert_many(nmdc_database[collection])\n",
    "print(sorted(db.list_collection_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FICUS Brodie spreadsheet and create gold-id-to-igsn map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLD_ID_IDX = 5\n",
    "IGSN_IDX = 2\n",
    "\n",
    "igsn_golds = defaultdict(list)\n",
    "\n",
    "gold_id_pattern = re.compile(r\"Gb\\d+\")\n",
    "\n",
    "with open('../src/data/FICUS_Soil_Gs0135149_Brodie-12-23-2020_PS.xlsx - Brodie_Gs0135149_Soil_Metadata.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        gold_id = row[GOLD_ID_IDX]\n",
    "        igsn = row[IGSN_IDX]\n",
    "        if gold_id_pattern.fullmatch(gold_id):\n",
    "            igsn_golds[igsn].append(gold_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare helper function to compare timestamps given in e.g. \"15-MAY-20 08.30.01.000000000 am\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pattern = re.compile(r\"\\d{2}-(?P<month>\\w+)-\\d{2} \\d{2}\\.\\d{2}\\.\\d{2}\\.(?P<ns>\\d+) [A|P]M\")\n",
    "dt_format = \"%d-%b-%y %I.%M.%S.%f %p\"\n",
    "\n",
    "def order_timestamps(timestamps):\n",
    "    if not all(isinstance(ts, str) for ts in timestamps):\n",
    "        raise Exception(f\"{timestamps} not strings\")\n",
    "    as_datetimes = []\n",
    "    for ts in timestamps:\n",
    "        match = dt_pattern.search(ts)\n",
    "        first, month, rest = ts.partition(match.group(\"month\"))\n",
    "        ts_new = first + month[0] + month[1:].lower() + rest\n",
    "        ts_new = ts_new.replace(match.group(\"ns\"), match.group(\"ns\")[:-3]) # truncate to microseconds\n",
    "        as_datetimes.append(datetime.strptime(ts_new, dt_format))\n",
    "    sorted_dts = sorted(as_datetimes)\n",
    "    return [dt.strftime(dt_format) for dt in sorted_dts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare helper-function pipeline to unify biosample_set documents that should be considered equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_xna_pattern = re.compile(r\"ER_[D|R]NA_\\d+$\")\n",
    "\n",
    "def rstrip_name_ER_ID(d):\n",
    "    s = get_in([\"name\"], d)\n",
    "    s_new = er_xna_pattern.split(s)[0] if er_xna_pattern.search(s) else s\n",
    "    return assoc_in(d, [\"name\"], s_new)\n",
    "\n",
    "def capitalize_location_raw_value(d):\n",
    "    s = get_in([\"location\", \"has_raw_value\"], d)\n",
    "    s_new = s[0].upper() + s[1:]\n",
    "    return assoc_in(d, [\"location\", \"has_raw_value\"], s_new)\n",
    "\n",
    "pipeline = compose(\n",
    "    capitalize_location_raw_value,\n",
    "    rstrip_name_ER_ID,\n",
    "    lambda d: dissoc(d, \"_id\", \"id\", \"add_date\", \"mod_date\", \"identifier\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce new biosample objects with ISGN ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_biosample_docs = []\n",
    "\n",
    "for igsn, golds in igsn_golds.items():\n",
    "    igsn_curie = \"igsn:\"+igsn\n",
    "    to_change = list(db.biosample_set.find({\"id\": {\"$in\": [f\"gold:{g}\" for g in golds]}}))\n",
    "    \n",
    "    # No merge needed, just change of id.\n",
    "    if len(to_change) == 1:\n",
    "        merged = assoc_in(to_change[0], [\"id\"], igsn_curie)\n",
    "        merged = assoc_in(merged, [\"identifier\", \"has_raw_value\"], igsn_curie)\n",
    "        merged_biosample_docs.append(merged)\n",
    "        continue\n",
    "\n",
    "    # Ensure that unification pipeline is adequate to resolve differences.\n",
    "    distilled = list(map(pipeline, to_change))\n",
    "    result = list(diff(distilled[0], distilled[1]))\n",
    "    assert result == []\n",
    "    \n",
    "    # Produce a merged document\n",
    "    earlier_ts, _ = order_timestamps([get_in([\"add_date\", \"has_raw_value\"], d) for d in to_change])\n",
    "    merged = assoc_in(distilled[0], [\"add_date\", \"has_raw_value\"], earlier_ts)\n",
    "    _, later_ts = order_timestamps([get_in([\"mod_date\", \"has_raw_value\"], d) for d in to_change])\n",
    "    merged = assoc_in(merged, [\"mod_date\", \"has_raw_value\"], later_ts)\n",
    "    merged = assoc_in(merged, [\"id\"], igsn_curie)\n",
    "    merged = assoc_in(merged, [\"identifier\", \"has_raw_value\"], igsn_curie)\n",
    "    \n",
    "    merged_biosample_docs.append(merged)\n",
    "    merged = None # defense against accidental reuse during next iteration.\n",
    "\n",
    "assert len(merged_biosample_docs) == len(igsn_golds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete old biosample objects and insert new ones in one bulk-write operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 48)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests = [DeleteMany({\"id\": {\"$in\": [\"gold:\"+g for g in concat(igsn_golds.values())]}})]\n",
    "requests.extend([InsertOne(d) for d in merged_biosample_docs])\n",
    "result = db.biosample_set.bulk_write(requests)\n",
    "result.deleted_count, result.inserted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update omics_processing_set references to biosample_set ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldid_igsn = {}\n",
    "for igsn, gids in igsn_golds.items():\n",
    "    for gid in gids:\n",
    "        goldid_igsn[gid] = igsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "to_replace = {\"gold:\"+k: \"igsn:\"+v for k, v in goldid_igsn.items()}\n",
    "\n",
    "for doc in db.omics_processing_set.find({\"$or\": [\n",
    "    {\"id\": {\"$in\": list(to_replace)}},\n",
    "    {\"has_input\": {\"$in\": list(to_replace)}},\n",
    "    {\"has_output\": {\"$in\": list(to_replace)}},\n",
    "    {\"part_of\": {\"$in\": list(to_replace)}}\n",
    "]}):\n",
    "    operations = {\"$set\": {\n",
    "        \"id\": to_replace.get(doc[\"id\"], doc[\"id\"]),\n",
    "        \"has_input\": [to_replace.get(i, i) for i in doc[\"has_input\"]],\n",
    "        \"has_output\": [to_replace.get(i, i) for i in doc[\"has_output\"]],\n",
    "        \"part_of\": [to_replace.get(i, i) for i in doc[\"part_of\"]],\n",
    "    }}\n",
    "    requests.append({\"filter\": {\"_id\": doc[\"_id\"]}, \"update\": operations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = db.omics_processing_set.bulk_write([UpdateOne(**r) for r in requests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv.modified_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update omics_processing_set references from EMSL ids to IGSNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMSL_IDS_IDX = 7\n",
    "IGSN_IDX = 2\n",
    "\n",
    "igsn_emsls = {}\n",
    "\n",
    "emsl_ids_pattern = re.compile(r\"\\d+\")\n",
    "\n",
    "with open('../src/data/FICUS_Soil_Gs0135149_Brodie-12-23-2020_PS.xlsx - Brodie_Gs0135149_Soil_Metadata.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        emsl_ids = row[EMSL_IDS_IDX]\n",
    "        igsn = row[IGSN_IDX]\n",
    "        ids = emsl_ids_pattern.findall(emsl_ids)\n",
    "        # XXX some rows have emsl ids but no IGSN, so igsn.strip() check here\n",
    "        if igsn.strip() and ids:\n",
    "            igsn_emsls[igsn] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emslid_igsn = {}\n",
    "for igsn, eids in igsn_emsls.items():\n",
    "    for eid in eids:\n",
    "        emslid_igsn[eid] = igsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_with_emsl_id = db.omics_processing_set.count_documents(\n",
    "    {\"id\": {\"$in\": [\"emsl:\"+i for i in emslid_igsn]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "to_replace = {\"emsl:\"+k: \"igsn:\"+v for k, v in emslid_igsn.items()}\n",
    "to_replace.update({\"emsl:output_\"+k: \"igsn:\"+v for k, v in emslid_igsn.items()})\n",
    "\n",
    "for doc in db.omics_processing_set.find({\"$or\": [\n",
    "    {\"id\": {\"$in\": list(to_replace)}},\n",
    "    {\"has_input\": {\"$in\": list(to_replace)}},\n",
    "    {\"has_output\": {\"$in\": list(to_replace)}},\n",
    "    {\"part_of\": {\"$in\": list(to_replace)}}\n",
    "]}):\n",
    "    operations = {\"$set\": {\"id\": to_replace.get(doc[\"id\"], doc[\"id\"])}}\n",
    "    for field in [\"has_input\", \"has_output\", \"part_of\"]:\n",
    "        if field in doc:\n",
    "            operations[\"$set\"][field] = [to_replace.get(i, i) for i in doc[field]]\n",
    "    requests.append({\"filter\": {\"_id\": doc[\"_id\"]}, \"update\": operations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = db.omics_processing_set.bulk_write([UpdateOne(**r) for r in requests])\n",
    "assert n_with_emsl_id == rv.modified_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some newly IGSN id'ed docs identify as part_of biosamples without IGSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6008a50432e1b154f91ab624'),\n",
       " 'id': 'igsn:IEWFS000A',\n",
       " 'name': 'Brodie_134A_CHCl3_15Oct18_IAT_p1_1_01_35922',\n",
       " 'description': 'High resolution MS spectra only',\n",
       " 'part_of': ['gold:Gs0135149'],\n",
       " 'has_output': ['igsn:IEWFS000A'],\n",
       " 'omics_type': {'has_raw_value': 'Organic Matter Characterization'},\n",
       " 'type': 'nmdc:OmicsProcessing',\n",
       " 'instrument_name': {'has_raw_value': '12T_FTICR_B'},\n",
       " 'processing_institution': {'has_raw_value': 'Environmental Molecular Sciences Lab'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.omics_processing_set.find_one(\n",
    "    {\"id\": {\"$regex\": \"^igsn\"}, \"part_of\": {\"$regex\": \"^gold\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"gold:Gs0135149\" in goldid_igsn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdc",
   "language": "python",
   "name": "nmdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
